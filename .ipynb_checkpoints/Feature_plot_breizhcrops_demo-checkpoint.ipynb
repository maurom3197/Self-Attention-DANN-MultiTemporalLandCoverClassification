{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metropolitan-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "northern-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "import breizhcrops\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "treated-aircraft",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "statistical-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "subtle-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-fiber",
   "metadata": {},
   "source": [
    "# Define params and datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assured-undergraduate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mauromartini/mauro_ws/Remote_sensing_DANN/breizhcrops_dataset\n"
     ]
    }
   ],
   "source": [
    "# insert breizhcrops dataset path\n",
    "abs_path= '/home/mauromartini/mauro_ws/Remote_sensing_DANN/breizhcrops_dataset'\n",
    "# path = '.../breizhcrops_dataset'\n",
    "datapath = Path(abs_path)\n",
    "print(datapath)\n",
    "mode = 'all_zones'\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "\n",
    "weight_decay = 5e-08\n",
    "workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-conducting",
   "metadata": {},
   "source": [
    "# Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "experimental-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_load import *\n",
    "from utils.metrics import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "tender-england",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "loading data into RAM:   0%|          | 0/178632 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up datasets in /home/mauromartini/mauro_ws/Remote_sensing_DANN/breizhcrops_dataset, level L2A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading data into RAM: 100%|██████████| 178632/178632 [00:50<00:00, 3525.30it/s]\n",
      "loading data into RAM: 100%|██████████| 140782/140782 [00:40<00:00, 3509.10it/s]\n",
      "loading data into RAM: 100%|██████████| 166367/166367 [00:47<00:00, 3487.04it/s]\n",
      "loading data into RAM: 100%|██████████| 122708/122708 [00:35<00:00, 3492.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# if we want to import all zones data\n",
    "zone1dataset, zone2dataset, zone3dataset, zone4dataset, meta = get_datasets(datapath=datapath, mode=mode,\n",
    "                                                        batchsize=batch_size, \n",
    "                                                        preload_ram=True, level=\"L2A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sonic-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = meta[\"num_classes\"]\n",
    "ndims = meta[\"ndims\"]\n",
    "sequencelength = meta[\"sequencelength\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "pretty-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1dataloader, zone2dataloader, zone3dataloader, zone4dataloader = get_dataloader2(zone1dataset, zone2dataset, \n",
    "                                                                                     zone3dataset, zone4dataset,\n",
    "                                                                                     batchsize=batch_size, \n",
    "                                                                                     workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-mainland",
   "metadata": {},
   "source": [
    "# Define DANN Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "forward-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer params\n",
    "#ndims=10\n",
    "#num_classes=9\n",
    "#sequencelength=45\n",
    "        \n",
    "d_model=64\n",
    "n_head=2\n",
    "n_layers=3\n",
    "d_inner=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "living-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized TransformerEncoder_input-dim=10_num-classes=9_d-model=64_d-inner=128_n-layers=3_n-head=2_dropout=0.1_learning-rate=0.001_weight-decay=5e-08\n",
      "Initialized TransformerEncoder_input-dim=10_num-classes=9_d-model=64_d-inner=128_n-layers=3_n-head=2_dropout=0.1_learning-rate=0.001_weight-decay=5e-08\n",
      "Logging results to logs/torch_transformer_dann/\n"
     ]
    }
   ],
   "source": [
    "from utils.DANN_Transformer_model import ViTransformerExtractor, ViTransformerDANN\n",
    "\n",
    "feature_ex = ViTransformerExtractor(input_dim=ndims, n_head=n_head, n_layers=n_layers, \n",
    "                                    activation=\"relu\",).to(device)\n",
    "dann_model = ViTransformerDANN(feature_ex, input_dim=ndims, num_classes=num_classes, n_layers = n_layers, \n",
    "                                    n_domain=2,\n",
    "                                    activation=\"relu\",).to(device)\n",
    "\n",
    "dann_model.modelname += f\"_learning-rate={learning_rate}_weight-decay={weight_decay}\"\n",
    "print(f\"Initialized {dann_model.modelname}\")\n",
    "\n",
    "logdir = 'logs/torch_transformer_dann/'\n",
    "\n",
    "print(f\"Initialized {dann_model.modelname}\")\n",
    "os.makedirs(logdir, exist_ok=True)\n",
    "print(f\"Logging results to {logdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-glucose",
   "metadata": {},
   "source": [
    "# Test on single Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fixed-property",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss=1.26:   0%|          | 2/650 [00:00<00:55, 11.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target zone: zone3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test loss=1.12: 100%|██████████| 650/650 [00:51<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.6509223584004039, 'kappa': 0.5488366414465226, 'f1_micro': 0.6509223584004039, 'f1_macro': 0.4549411500589058, 'f1_weighted': 0.6572271819799855, 'recall_micro': 0.6509223584004039, 'recall_macro': 0.45683933527750864, 'recall_weighted': 0.6509223584004039, 'precision_micro': 0.6509223584004039, 'precision_macro': 0.4741012562357224, 'precision_weighted': 0.6819147640865526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauromartini/.virtualenvs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mauromartini/.virtualenvs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from utils.test import test_epoch\n",
    "\n",
    "dataloaders = [(zone1dataloader,'zone1'), (zone2dataloader,'zone2'), (zone3dataloader,'zone3'), (zone4dataloader,'zone4')]\n",
    "feature_ex = ViTransformerExtractor(input_dim=ndims, n_head = n_head, n_layers = n_layers, activation=\"relu\",).to(device)\n",
    "dann_model = ViTransformerDANN(feature_ex, input_dim=ndims, num_classes=num_classes,\n",
    "                                n_layers = n_layers, n_domain=2,activation=\"relu\",).to(device)\n",
    "\n",
    "path = 'models/vio_trasformer_dann_s2_t3_maxalpha02_gamma10/archive.zip'\n",
    "model_dir = Path(path)\n",
    "dann_model.load_state_dict(torch.load(model_dir))\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "# SET TARGET DATA\n",
    "ZONE = 3 #indicate the number of the desired target zone\n",
    "testdataloader = dataloaders[ZONE-1][0]\n",
    "test_zone = dataloaders[ZONE-1][1]\n",
    "print('Target zone:', test_zone)\n",
    "\n",
    "test_loss, y_true, y_pred, *_ = test_epoch(dann_model, criterion, testdataloader, device)\n",
    "\n",
    "scores = metrics(y_true.cpu(), y_pred.cpu())\n",
    "scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores.items()])\n",
    "\n",
    "test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-freeze",
   "metadata": {},
   "source": [
    "# Test on all zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.test import test_on_all_zones\n",
    "zones = 4\n",
    "dataloaders = [(zone1dataloader,'zone1'), (zone2dataloader,'zone2'), (zone3dataloader,'zone3'), (zone4dataloader,'zone4')]\n",
    "\n",
    "# DEFINE MODEL\n",
    "feature_ex = ViTransformerExtractor(input_dim=ndims, n_head = n_head, n_layers = n_layers, activation=\"relu\",).to(device)\n",
    "dann_model = ViTransformerDANN(feature_ex, input_dim=ndims, num_classes=num_classes,\n",
    "                                n_layers = n_layers, n_domain=2,activation=\"relu\",).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "for i in range(zones):\n",
    "    \n",
    "    traindataloader = dataloaders[i][0]\n",
    "    train_zone = dataloaders[i][1]\n",
    "    print('Source zone:', train_zone)\n",
    "    \n",
    "    for j in range(zones):\n",
    "        if j!= i:\n",
    "            # DEFINE MODE DIR AND NAME\n",
    "                # if alpha scheduled save model as:\n",
    "            path = 'models/vio_trasformer_dann_s'+str(i+1)+'_t'+ str(j+1)+'_maxalpha02_gamma'+str(gamma)\n",
    "                # if constant alpha save model as:\n",
    "            #path = 'models/vio_trasformer_dann_s'+str(i+1)+'_t'+ str(j+1)+'_alpha'+str(alpha_c)\n",
    "            model_dir = Path(path)\n",
    "            dann_model.load_state_dict(torch.load(model_dir))\n",
    "            \n",
    "            # SET TARGET DATA\n",
    "            testdataloader = dataloaders[j][0]\n",
    "            test_zone = dataloaders[j][1]\n",
    "            print('Target zone:', test_zone)\n",
    "\n",
    "            test_loss, y_true, y_pred, *_ = test_epoch(dann_model, criterion, testdataloader, device)\n",
    "\n",
    "            scores = metrics(y_true.cpu(), y_pred.cpu())\n",
    "            scores_msg = \", \".join([f\"{k}={v:.2f}\" for (k, v) in scores.items()])\n",
    "            test_loss = test_loss.cpu().detach().numpy()[0]\n",
    "            print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-parent",
   "metadata": {},
   "source": [
    "# Feature Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-rider",
   "metadata": {},
   "source": [
    "# 2D Features plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualize_results import extract_features, plot2Dpca\n",
    "from utils.metrics import MMD\n",
    "\n",
    "dataloaders = [(zone1dataloader,'zone1'), (zone2dataloader,'zone2'), (zone3dataloader,'zone3'), (zone4dataloader,'zone4')]\n",
    "num_categories = 9\n",
    "alpha_c = 0.2\n",
    "gamma = 10\n",
    "\n",
    "source = 1\n",
    "target = 2\n",
    "\n",
    "traindataloader = dataloaders[source][0]\n",
    "train_zone = dataloaders[source][1]\n",
    "print('Training zone:', train_zone)\n",
    "\n",
    "testdl = dataloaders[target][0]\n",
    "test_zone = dataloaders[target][1]\n",
    "print('Testing zone:', test_zone)\n",
    "source_zone = train_zone\n",
    "target_zone = test_zone\n",
    "\n",
    "path = 'models/vio_trasformer_dann_s2_t3_maxalpha02_gamma10/archive.zip'\n",
    "#path = 'models/torch_transformer/vio_trasformer_dann_s'+str(source+1)+'_t'+ str(target+1)+'_gamma'+str(gamma)\n",
    "#path = 'models/torch_transformer/vio_trasformer_dann_s'+str(source+1)+'_t'+ str(target+1)+'_maxalpha02_gamma'+str(gamma)\n",
    "model_dir = Path(path)\n",
    "dann_model.load_state_dict(torch.load(model_dir))\n",
    "\n",
    "train_embeddings, train_targets, train_predictions = extract_features(dann_model, traindataloader, device)\n",
    "pca_train_embs = plot2Dpca(train_zone, source_zone, target_zone, train_embeddings, train_targets, train_predictions, save_plot = True)\n",
    "\n",
    "test_embeddings, test_targets, test_predictions = extract_features(dann_model, testdl, device)\n",
    "pca_test_embs = plot2Dpca(test_zone, source_zone, target_zone, test_embeddings, test_targets, test_predictions, save_plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-track",
   "metadata": {},
   "source": [
    "# Compute MMD metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embs = torch.as_tensor(train_embeddings)\n",
    "test_embs = torch.as_tensor(test_embeddings)\n",
    "\n",
    "mmd = MMD(train_embs, test_embs, 'rbf')\n",
    "mmd = mmd.detach().cpu().numpy()\n",
    "print('MMD for source zone {} - target zone {}: '.format(str(source+1), str(target+1)), mmd)\n",
    "mmd_results.append(mmd)\n",
    "mmd_results = np.asarray(mmd_results)\n",
    "print('MMD results for zone {}: '.format(str(source+1)), mmd_results)\n",
    "\n",
    "# save results\n",
    "np.save('results/DANN/'+train_zone+'/MMD_results_zone{}'.format(str(source+1)), mmd_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-costa",
   "metadata": {},
   "source": [
    "# 3D features plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT 3D comparison of best and worst case\n",
    "dataloaders = [(zone1dataloader,'zone1'), (zone2dataloader,'zone2'), (zone3dataloader,'zone3'), (zone4dataloader,'zone4')]\n",
    "num_categories = 9\n",
    "gamma = 10\n",
    "\n",
    "# SELECT Source AND Target DOMAIN (REGION) to identify the model\n",
    "# Source\n",
    "source = 1 #zone number = i+1\n",
    "# Target\n",
    "target = 2 #zone number = i+1\n",
    "sourcedataloader = dataloaders[source][0]\n",
    "source_zone = dataloaders[source][1]\n",
    "print('Source zone:', source_zone)\n",
    "    \n",
    "targetdl = dataloaders[target][0]\n",
    "target_zone = dataloaders[target][1]\n",
    "print('Target zone:', target_zone)\n",
    "\n",
    "#BEST DANN MODEL = 2 --> 3 lambda max = 1\n",
    "path = 'models/vio_trasformer_dann_s2_t3_maxalpha02_gamma10/archive.zip'\n",
    "#path = 'models/torch_transformer/vio_trasformer_dann_s'+str(source+1)+'_t'+ str(target+1)+'_gamma'+str(gamma)\n",
    "model_dir = Path(path)\n",
    "dann_model.load_state_dict(torch.load(model_dir))\n",
    "\n",
    "source_embeddings, source_targets, source_predictions = extract_features(dann_model, sourcedataloader, device)\n",
    "target_embeddings, target_targets, target_predictions = extract_features(dann_model, targetdl, device)\n",
    "\n",
    "image_name = '3Dfeature_pca_BESTmodel_'+source_zone+target_zone\n",
    "plot3D_source_target(source_zone, target_zone, \n",
    "                     source_embeddings, source_targets, source_predictions,\n",
    "                     target_embeddings, target_targets, target_predictions,\n",
    "                     image_name,\n",
    "                     save_plot = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
